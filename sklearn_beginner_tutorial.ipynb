{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn 初級チュートリアル\n",
    "\n",
    "このチュートリアルでは、Python の機械学習ライブラリ **scikit-learn** の基本を学びます。教師あり学習の基礎から、モデルの評価方法まで習得しましょう。\n",
    "\n",
    "## 学習内容\n",
    "1. scikit-learn の概要と基本的な使い方\n",
    "2. データの前処理\n",
    "3. 線形回帰\n",
    "4. ロジスティック回帰（分類）\n",
    "5. 決定木\n",
    "6. モデルの評価\n",
    "7. 交差検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JupyterLite 環境でのパッケージインストール\n",
    "import sys\n",
    "if 'pyodide' in sys.modules:\n",
    "    import piplite\n",
    "    await piplite.install(['numpy', 'pandas', 'matplotlib', 'scikit-learn'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "print(f'scikit-learn version: {sklearn.__version__}')\n",
    "\n",
    "# 警告を抑制\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 乱数シード\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. scikit-learn の概要と基本的な使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 scikit-learn の特徴\n",
    "\n",
    "- **一貫したAPI**: すべてのモデルが同じインターフェースを持つ\n",
    "  - `fit()`: モデルの学習\n",
    "  - `predict()`: 予測\n",
    "  - `score()`: 評価\n",
    "- **豊富なアルゴリズム**: 回帰、分類、クラスタリング、次元削減など\n",
    "- **前処理ツール**: スケーリング、エンコーディング、欠損値処理\n",
    "- **モデル評価**: 交差検証、グリッドサーチなど"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 サンプルデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_diabetes\n",
    "\n",
    "# iris データセット（分類用）\n",
    "iris = load_iris()\n",
    "print('=== Iris Dataset ===')\n",
    "print(f'特徴量: {iris.feature_names}')\n",
    "print(f'クラス: {iris.target_names}')\n",
    "print(f'データ形状: {iris.data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameに変換\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['target'] = iris.target\n",
    "df_iris['species'] = df_iris['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes データセット（回帰用）\n",
    "diabetes = load_diabetes()\n",
    "print('\\n=== Diabetes Dataset ===')\n",
    "print(f'特徴量: {diabetes.feature_names}')\n",
    "print(f'データ形状: {diabetes.data.shape}')\n",
    "print(f'ターゲット形状: {diabetes.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 基本的なワークフロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. データの分割\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f'訓練データ: {X_train.shape}')\n",
    "print(f'テストデータ: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. モデルの作成と学習\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('モデル学習完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 予測\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'予測結果（先頭10件）: {y_pred[:10]}')\n",
    "print(f'正解ラベル（先頭10件）: {y_test[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 評価\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'正解率: {accuracy:.4f}')\n",
    "\n",
    "# score メソッドでも同じ結果\n",
    "print(f'score: {model.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 特徴量のスケーリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# サンプルデータ\n",
    "X = np.array([[1, 100],\n",
    "              [2, 200],\n",
    "              [3, 300],\n",
    "              [4, 400],\n",
    "              [5, 500]])\n",
    "\n",
    "print('元のデータ:')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化（平均0、標準偏差1）\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print('標準化後:')\n",
    "print(X_standard)\n",
    "print(f'平均: {X_standard.mean(axis=0)}')\n",
    "print(f'標準偏差: {X_standard.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max スケーリング（0-1の範囲）\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X)\n",
    "\n",
    "print('Min-Max スケーリング後:')\n",
    "print(X_minmax)\n",
    "print(f'最小値: {X_minmax.min(axis=0)}')\n",
    "print(f'最大値: {X_minmax.max(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 カテゴリ変数のエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# サンプルデータ\n",
    "colors = ['red', 'blue', 'green', 'red', 'blue']\n",
    "\n",
    "# ラベルエンコーディング\n",
    "label_encoder = LabelEncoder()\n",
    "colors_encoded = label_encoder.fit_transform(colors)\n",
    "\n",
    "print('ラベルエンコーディング:')\n",
    "print(f'元: {colors}')\n",
    "print(f'変換後: {colors_encoded}')\n",
    "print(f'クラス: {label_encoder.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot エンコーディング\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "colors_onehot = onehot_encoder.fit_transform(np.array(colors).reshape(-1, 1))\n",
    "\n",
    "print('One-Hot エンコーディング:')\n",
    "print(colors_onehot)\n",
    "print(f'カテゴリ: {onehot_encoder.categories_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 欠損値の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 欠損値を含むデータ\n",
    "X_missing = np.array([[1, 2, np.nan],\n",
    "                      [3, np.nan, 6],\n",
    "                      [7, 8, 9],\n",
    "                      [np.nan, 11, 12]])\n",
    "\n",
    "print('欠損値を含むデータ:')\n",
    "print(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値で補完\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "X_imputed_mean = imputer_mean.fit_transform(X_missing)\n",
    "\n",
    "print('平均値で補完:')\n",
    "print(X_imputed_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中央値で補完\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "X_imputed_median = imputer_median.fit_transform(X_missing)\n",
    "\n",
    "print('中央値で補完:')\n",
    "print(X_imputed_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習問題 2\n",
    "\n",
    "iris データセットの特徴量を標準化し、訓練データとテストデータに分割してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習問題 2 の解答をここに書いてください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 単回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# サンプルデータの作成\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2 * X.flatten() + 3 + np.random.randn(100) * 2\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, alpha=0.7)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sample Data for Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f'切片 (intercept): {model.intercept_:.4f}')\n",
    "print(f'係数 (coefficient): {model.coef_[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回帰直線の可視化\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, alpha=0.7, label='Data')\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title(f'y = {model.coef_[0]:.2f}x + {model.intercept_:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 重回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes データセットを使用\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの学習\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 係数の確認\n",
    "print('各特徴量の係数:')\n",
    "for name, coef in zip(diabetes.feature_names, model.coef_):\n",
    "    print(f'  {name}: {coef:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 予測と評価\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred):.2f}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}')\n",
    "print(f'R²: {r2_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値 vs 実測値のプロット\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ロジスティック回帰（分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# iris データセット（2クラスに限定）\n",
    "X = iris.data[iris.target != 2]\n",
    "y = iris.target[iris.target != 2]\n",
    "\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 予測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('=== 分類結果 ===')\n",
    "print(f'正解率: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('混同行列:')\n",
    "print(cm)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類レポート\n",
    "print('分類レポート:')\n",
    "print(classification_report(y_test, y_pred, target_names=['setosa', 'versicolor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率の予測\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print('予測確率（先頭5件）:')\n",
    "print(y_prob[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 多クラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全クラスを使用\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 多クラス分類\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'正解率: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print('\\n分類レポート:')\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 決定木分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# データ準備\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# モデルの学習\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 評価\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(f'正解率: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree_model, \n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "          filled=True,\n",
    "          rounded=True)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の重要度\n",
    "importance = tree_model.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(iris.feature_names, importance)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 決定木回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# サンプルデータ\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.randn(100) * 0.1\n",
    "\n",
    "# 異なる深さのモデル\n",
    "depths = [2, 4, 8]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, depth in zip(axes, depths):\n",
    "    model = DecisionTreeRegressor(max_depth=depth)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    X_test = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ax.scatter(X, y, alpha=0.5, label='Data')\n",
    "    ax.plot(X_test, y_pred, color='red', linewidth=2, label='Prediction')\n",
    "    ax.set_title(f'max_depth={depth}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 分類モデルの評価指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# 2クラス分類の例\n",
    "X = iris.data[iris.target != 2]\n",
    "y = iris.target[iris.target != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('=== 分類評価指標 ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred):.4f}')\n",
    "print(f'AUC:       {roc_auc_score(y_test, y_prob):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_prob):.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 回帰モデルの評価指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# diabetes データセット\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('=== 回帰評価指標 ===')\n",
    "print(f'MAE:  {mean_absolute_error(y_test, y_pred):.4f}')\n",
    "print(f'MSE:  {mean_squared_error(y_test, y_pred):.4f}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}')\n",
    "print(f'R²:   {r2_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# iris データセット\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# モデル\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# 5分割交差検証\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('交差検証スコア:')\n",
    "print(f'各フォールドのスコア: {scores}')\n",
    "print(f'平均スコア: {scores.mean():.4f}')\n",
    "print(f'標準偏差: {scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold を明示的に使用\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "print('シャッフル付き交差検証:')\n",
    "print(f'平均スコア: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異なる評価指標での交差検証\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "print('複数指標での交差検証:')\n",
    "for metric in scoring:\n",
    "    scores = results[f'test_{metric}']\n",
    "    print(f'{metric}: {scores.mean():.4f} (+/- {scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習問題 7\n",
    "\n",
    "wine データセットを使って以下を実行してください。\n",
    "\n",
    "1. 決定木分類器を学習させる（max_depth=5）\n",
    "2. 5分割交差検証でモデルを評価する\n",
    "3. 特徴量の重要度を棒グラフで可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習問題 7 の解答をここに書いてください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## まとめ\n",
    "\n",
    "このチュートリアルで学んだ内容：\n",
    "\n",
    "| トピック | 主なクラス・関数 |\n",
    "|---------|---------------|\n",
    "| 前処理 | `StandardScaler`, `MinMaxScaler`, `LabelEncoder`, `SimpleImputer` |\n",
    "| 線形回帰 | `LinearRegression` |\n",
    "| 分類 | `LogisticRegression`, `DecisionTreeClassifier` |\n",
    "| 評価（分類） | `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score` |\n",
    "| 評価（回帰） | `mean_squared_error`, `mean_absolute_error`, `r2_score` |\n",
    "| 交差検証 | `cross_val_score`, `cross_validate`, `KFold` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 練習問題の解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習問題 2 の解答例\n",
    "print('--- 練習問題 2 ---')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データ\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 訓練・テスト分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 標準化（訓練データでfitしてテストデータに適用）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'訓練データ形状: {X_train_scaled.shape}')\n",
    "print(f'訓練データ平均: {X_train_scaled.mean(axis=0)}')\n",
    "print(f'訓練データ標準偏差: {X_train_scaled.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習問題 7 の解答例\n",
    "print('--- 練習問題 7 ---')\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# データ読み込み\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# 1. 決定木分類器\n",
    "tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# 2. 交差検証\n",
    "scores = cross_val_score(tree_model, X, y, cv=5)\n",
    "print(f'交差検証スコア: {scores}')\n",
    "print(f'平均スコア: {scores.mean():.4f} (+/- {scores.std():.4f})')\n",
    "\n",
    "# 3. 特徴量重要度の可視化\n",
    "importance = tree_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh([wine.feature_names[i] for i in indices], importance[indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Wine Dataset)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
