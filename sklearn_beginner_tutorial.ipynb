{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# JupyterLite ã§å­¦ã¶ scikit-learn åˆç´šãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«\n\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€**JupyterLiteï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã ã‘ã§å‹•ã Jupyter ç’°å¢ƒï¼‰** ä¸Šã§ã€\nPython ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª **scikit-learn** ã®åŸºç¤ã‚’ä¸€ã‹ã‚‰å­¦ã¶ãŸã‚ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã™ã€‚\n\n## å¯¾è±¡è€…\n- Python ã¨ NumPy/pandas ã®åŸºæœ¬ã‚’ç†è§£ã—ã¦ã„ã‚‹æ–¹\n- æ©Ÿæ¢°å­¦ç¿’ã‚’åˆã‚ã¦å­¦ã¶æ–¹ã€ã¾ãŸã¯åŸºç¤ã‚’å¾©ç¿’ã—ãŸã„æ–¹\n\n## ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§å­¦ã¶ã“ã¨\n1. scikit-learn ã®æ¦‚è¦ã¨åŸºæœ¬çš„ãªä½¿ã„æ–¹\n2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†\n3. ç·šå½¢å›å¸°\n4. ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆåˆ†é¡ï¼‰\n5. æ±ºå®šæœ¨\n6. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\n7. äº¤å·®æ¤œè¨¼"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. ç’°å¢ƒæº–å‚™ï¼ˆJupyterLite ç”¨ï¼‰\n\nã¾ãšã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# JupyterLite ç”¨ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\ntry:\n    import piplite\n    await piplite.install(['numpy', 'pandas', 'matplotlib', 'scikit-learn'])\nexcept ImportError:\n    pass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport sklearn\nprint(f'scikit-learn ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sklearn.__version__}')\n\n# è­¦å‘Šã‚’æŠ‘åˆ¶\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ä¹±æ•°ã‚·ãƒ¼ãƒ‰\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. scikit-learn ã®æ¦‚è¦ã¨åŸºæœ¬çš„ãªä½¿ã„æ–¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 scikit-learn ã®ç‰¹å¾´\n",
    "\n",
    "- **ä¸€è²«ã—ãŸAPI**: ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æŒã¤\n",
    "  - `fit()`: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "  - `predict()`: äºˆæ¸¬\n",
    "  - `score()`: è©•ä¾¡\n",
    "- **è±Šå¯Œãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: å›å¸°ã€åˆ†é¡ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€æ¬¡å…ƒå‰Šæ¸›ãªã©\n",
    "- **å‰å‡¦ç†ãƒ„ãƒ¼ãƒ«**: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€æ¬ æå€¤å‡¦ç†\n",
    "- **ãƒ¢ãƒ‡ãƒ«è©•ä¾¡**: äº¤å·®æ¤œè¨¼ã€ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒãªã©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_diabetes\n",
    "\n",
    "# iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåˆ†é¡ç”¨ï¼‰\n",
    "iris = load_iris()\n",
    "print('=== Iris Dataset ===')\n",
    "print(f'ç‰¹å¾´é‡: {iris.feature_names}')\n",
    "print(f'ã‚¯ãƒ©ã‚¹: {iris.target_names}')\n",
    "print(f'ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {iris.data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameã«å¤‰æ›\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['target'] = iris.target\n",
    "df_iris['species'] = df_iris['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå›å¸°ç”¨ï¼‰\n",
    "diabetes = load_diabetes()\n",
    "print('\\n=== Diabetes Dataset ===')\n",
    "print(f'ç‰¹å¾´é‡: {diabetes.feature_names}')\n",
    "print(f'ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {diabetes.data.shape}')\n",
    "print(f'ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå½¢çŠ¶: {diabetes.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 åŸºæœ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f'è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}')\n",
    "print(f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨å­¦ç¿’\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. äºˆæ¸¬\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'äºˆæ¸¬çµæœï¼ˆå…ˆé ­10ä»¶ï¼‰: {y_pred[:10]}')\n",
    "print(f'æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆå…ˆé ­10ä»¶ï¼‰: {y_test[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. è©•ä¾¡\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'æ­£è§£ç‡: {accuracy:.4f}')\n",
    "\n",
    "# score ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚‚åŒã˜çµæœ\n",
    "print(f'score: {model.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "X = np.array([[1, 100],\n",
    "              [2, 200],\n",
    "              [3, 300],\n",
    "              [4, 400],\n",
    "              [5, 500]])\n",
    "\n",
    "print('å…ƒã®ãƒ‡ãƒ¼ã‚¿:')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰\n",
    "scaler_standard = StandardScaler()\n",
    "X_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "print('æ¨™æº–åŒ–å¾Œ:')\n",
    "print(X_standard)\n",
    "print(f'å¹³å‡: {X_standard.mean(axis=0)}')\n",
    "print(f'æ¨™æº–åå·®: {X_standard.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆ0-1ã®ç¯„å›²ï¼‰\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X)\n",
    "\n",
    "print('Min-Max ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œ:')\n",
    "print(X_minmax)\n",
    "print(f'æœ€å°å€¤: {X_minmax.min(axis=0)}')\n",
    "print(f'æœ€å¤§å€¤: {X_minmax.max(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "colors = ['red', 'blue', 'green', 'red', 'blue']\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "label_encoder = LabelEncoder()\n",
    "colors_encoded = label_encoder.fit_transform(colors)\n",
    "\n",
    "print('ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°:')\n",
    "print(f'å…ƒ: {colors}')\n",
    "print(f'å¤‰æ›å¾Œ: {colors_encoded}')\n",
    "print(f'ã‚¯ãƒ©ã‚¹: {label_encoder.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "colors_onehot = onehot_encoder.fit_transform(np.array(colors).reshape(-1, 1))\n",
    "\n",
    "print('One-Hot ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°:')\n",
    "print(colors_onehot)\n",
    "print(f'ã‚«ãƒ†ã‚´ãƒª: {onehot_encoder.categories_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æ¬ æå€¤ã®å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# æ¬ æå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "X_missing = np.array([[1, 2, np.nan],\n",
    "                      [3, np.nan, 6],\n",
    "                      [7, 8, 9],\n",
    "                      [np.nan, 11, 12]])\n",
    "\n",
    "print('æ¬ æå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿:')\n",
    "print(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¹³å‡å€¤ã§è£œå®Œ\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "X_imputed_mean = imputer_mean.fit_transform(X_missing)\n",
    "\n",
    "print('å¹³å‡å€¤ã§è£œå®Œ:')\n",
    "print(X_imputed_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸­å¤®å€¤ã§è£œå®Œ\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "X_imputed_median = imputer_median.fit_transform(X_missing)\n",
    "\n",
    "print('ä¸­å¤®å€¤ã§è£œå®Œ:')\n",
    "print(X_imputed_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ğŸ“ 2ç«  ç·´ç¿’å•é¡Œ\n\niris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ã—ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ã¦ãã ã•ã„ã€‚"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç·´ç¿’å•é¡Œã®è§£ç­”æ¬„\n\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ç·šå½¢å›å¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 å˜å›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2 * X.flatten() + 3 + np.random.randn(100) * 2\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, alpha=0.7)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sample Data for Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f'åˆ‡ç‰‡ (intercept): {model.intercept_:.4f}')\n",
    "print(f'ä¿‚æ•° (coefficient): {model.coef_[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å›å¸°ç›´ç·šã®å¯è¦–åŒ–\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, alpha=0.7, label='Data')\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title(f'y = {model.coef_[0]:.2f}x + {model.intercept_:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 é‡å›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ä¿‚æ•°ã®ç¢ºèª\n",
    "print('å„ç‰¹å¾´é‡ã®ä¿‚æ•°:')\n",
    "for name, coef in zip(diabetes.feature_names, model.coef_):\n",
    "    print(f'  {name}: {coef:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# äºˆæ¸¬ã¨è©•ä¾¡\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred):.2f}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}')\n",
    "print(f'RÂ²: {r2_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆåˆ†é¡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ2ã‚¯ãƒ©ã‚¹ã«é™å®šï¼‰\n",
    "X = iris.data[iris.target != 2]\n",
    "y = iris.target[iris.target != 2]\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# äºˆæ¸¬\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('=== åˆ†é¡çµæœ ===')\n",
    "print(f'æ­£è§£ç‡: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ··åŒè¡Œåˆ—\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('æ··åŒè¡Œåˆ—:')\n",
    "print(cm)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ\n",
    "print('åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:')\n",
    "print(classification_report(y_test, y_pred, target_names=['setosa', 'versicolor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¢ºç‡ã®äºˆæ¸¬\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print('äºˆæ¸¬ç¢ºç‡ï¼ˆå…ˆé ­5ä»¶ï¼‰:')\n",
    "print(y_prob[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 å¤šã‚¯ãƒ©ã‚¹åˆ†é¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¨ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# å¤šã‚¯ãƒ©ã‚¹åˆ†é¡\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'æ­£è§£ç‡: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print('\\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:')\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. æ±ºå®šæœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 æ±ºå®šæœ¨åˆ†é¡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# è©•ä¾¡\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(f'æ­£è§£ç‡: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ±ºå®šæœ¨ã®å¯è¦–åŒ–\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree_model, \n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "          filled=True,\n",
    "          rounded=True)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ã®é‡è¦åº¦\n",
    "importance = tree_model.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(iris.feature_names, importance)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 æ±ºå®šæœ¨å›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.randn(100) * 0.1\n",
    "\n",
    "# ç•°ãªã‚‹æ·±ã•ã®ãƒ¢ãƒ‡ãƒ«\n",
    "depths = [2, 4, 8]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, depth in zip(axes, depths):\n",
    "    model = DecisionTreeRegressor(max_depth=depth)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    X_test = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ax.scatter(X, y, alpha=0.5, label='Data')\n",
    "    ax.plot(X_test, y_pred, color='red', linewidth=2, label='Prediction')\n",
    "    ax.set_title(f'max_depth={depth}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# 2ã‚¯ãƒ©ã‚¹åˆ†é¡ã®ä¾‹\n",
    "X = iris.data[iris.target != 2]\n",
    "y = iris.target[iris.target != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('=== åˆ†é¡è©•ä¾¡æŒ‡æ¨™ ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred):.4f}')\n",
    "print(f'AUC:       {roc_auc_score(y_test, y_prob):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROCæ›²ç·š\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_prob):.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# diabetes ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('=== å›å¸°è©•ä¾¡æŒ‡æ¨™ ===')\n",
    "print(f'MAE:  {mean_absolute_error(y_test, y_pred):.4f}')\n",
    "print(f'MSE:  {mean_squared_error(y_test, y_pred):.4f}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}')\n",
    "print(f'RÂ²:   {r2_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. äº¤å·®æ¤œè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# 5åˆ†å‰²äº¤å·®æ¤œè¨¼\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢:')\n",
    "print(f'å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚³ã‚¢: {scores}')\n",
    "print(f'å¹³å‡ã‚¹ã‚³ã‚¢: {scores.mean():.4f}')\n",
    "print(f'æ¨™æº–åå·®: {scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold ã‚’æ˜ç¤ºçš„ã«ä½¿ç”¨\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "print('ã‚·ãƒ£ãƒƒãƒ•ãƒ«ä»˜ãäº¤å·®æ¤œè¨¼:')\n",
    "print(f'å¹³å‡ã‚¹ã‚³ã‚¢: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç•°ãªã‚‹è©•ä¾¡æŒ‡æ¨™ã§ã®äº¤å·®æ¤œè¨¼\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "print('è¤‡æ•°æŒ‡æ¨™ã§ã®äº¤å·®æ¤œè¨¼:')\n",
    "for metric in scoring:\n",
    "    scores = results[f'test_{metric}']\n",
    "    print(f'{metric}: {scores.mean():.4f} (+/- {scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ğŸ“ 7ç«  ç·´ç¿’å•é¡Œ\n\nwine ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n\n1. æ±ºå®šæœ¨åˆ†é¡å™¨ã‚’å­¦ç¿’ã•ã›ã‚‹ï¼ˆmax_depth=5ï¼‰\n2. 5åˆ†å‰²äº¤å·®æ¤œè¨¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹\n3. ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’æ£’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã™ã‚‹"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç·´ç¿’å•é¡Œã®è§£ç­”æ¬„\n\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## ã¾ã¨ã‚\n\nã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§å­¦ã‚“ã ã“ã¨ã‚’ã¾ã¨ã‚ã¾ã™ï¼š\n\n| ãƒˆãƒ”ãƒƒã‚¯ | ä¸»ãªã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•° |\n|---------|---------------|\n| å‰å‡¦ç† | `StandardScaler`, `MinMaxScaler`, `LabelEncoder`, `SimpleImputer` |\n| ç·šå½¢å›å¸° | `LinearRegression` |\n| åˆ†é¡ | `LogisticRegression`, `DecisionTreeClassifier` |\n| è©•ä¾¡ï¼ˆåˆ†é¡ï¼‰ | `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score` |\n| è©•ä¾¡ï¼ˆå›å¸°ï¼‰ | `mean_squared_error`, `mean_absolute_error`, `r2_score` |\n| äº¤å·®æ¤œè¨¼ | `cross_val_score`, `cross_validate`, `KFold` |\n\n## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n\nåˆç´šã‚’çµ‚ãˆãŸã‚‰ã€**scikit-learn ä¸­ç´šãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«** ã§ä»¥ä¸‹ã‚’å­¦ã³ã¾ã—ã‚‡ã†ï¼š\n- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼‰\n- ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³\n- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGridSearchCVï¼‰\n- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰\n- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## ç·åˆæ¼”ç¿’\n\nã“ã‚Œã¾ã§å­¦ã‚“ã å†…å®¹ã‚’ä½¿ã£ã¦ã€ä»¥ä¸‹ã®èª²é¡Œã«æŒ‘æˆ¦ã—ã¦ãã ã•ã„ã€‚\n\n### èª²é¡Œï¼šãƒ¯ã‚¤ãƒ³ã®å“è³ªåˆ†é¡\n\nwine ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ãªã•ã„ï¼š\n\n1. **ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**\n   - wine ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€\n   - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆ70%ï¼‰ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆ30%ï¼‰ã«åˆ†å‰²\n   - ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–\n\n2. **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ**\n   - ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨æ±ºå®šæœ¨ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n   - ä¸¡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’è¡Œã†\n\n3. **è©•ä¾¡ã¨æ¯”è¼ƒ**\n   - å„ãƒ¢ãƒ‡ãƒ«ã®æ­£è§£ç‡ã€é©åˆç‡ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n   - æ··åŒè¡Œåˆ—ã‚’å¯è¦–åŒ–\n   - ã©ã¡ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚Œã¦ã„ã‚‹ã‹è€ƒå¯Ÿ\n\n4. **äº¤å·®æ¤œè¨¼**\n   - 5åˆ†å‰²äº¤å·®æ¤œè¨¼ã§ä¸¡ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡\n   - çµæœã‚’æ¯”è¼ƒ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç·åˆæ¼”ç¿’ã®è§£ç­”æ¬„\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç·´ç¿’å•é¡Œ 7 ã®è§£ç­”ä¾‹\n",
    "print('--- ç·´ç¿’å•é¡Œ 7 ---')\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# 1. æ±ºå®šæœ¨åˆ†é¡å™¨\n",
    "tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# 2. äº¤å·®æ¤œè¨¼\n",
    "scores = cross_val_score(tree_model, X, y, cv=5)\n",
    "print(f'äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢: {scores}')\n",
    "print(f'å¹³å‡ã‚¹ã‚³ã‚¢: {scores.mean():.4f} (+/- {scores.std():.4f})')\n",
    "\n",
    "# 3. ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–\n",
    "importance = tree_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh([wine.feature_names[i] for i in indices], importance[indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Wine Dataset)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}