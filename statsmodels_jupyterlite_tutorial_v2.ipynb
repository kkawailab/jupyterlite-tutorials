{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d18e58",
   "metadata": {},
   "source": [
    "# JupyterLite で学ぶ statsmodels 入門チュートリアル\n",
    "\n",
    "JupyterLite（ブラウザだけで動く Jupyter 環境）上で、`statsmodels` を用いた基本的な統計モデリング（回帰分析・検定など）を体験するためのノートブックです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a00883",
   "metadata": {},
   "source": [
    "## 0. 環境準備（JupyterLite 用）\n",
    "\n",
    "このノートブックは **JupyterLite（Pyodide）** 上で動かすことを想定しています。\n",
    "\n",
    "まず、必要なパッケージをインストール（またはロード）します。\n",
    "\n",
    "環境によってはすでにインストール済みの場合もありますが、\n",
    "エラーが出た場合は、次のセルを上から順に実行して確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35da42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じて piplite / micropip を利用してパッケージをインストールします。\n",
    "# すでにインストール済みの環境では、このセルはスキップまたは実行しても何も起こらない場合があります。\n",
    "\n",
    "try:\n",
    "    import piplite\n",
    "    # JupyterLite サイト側で wheel が用意されている場合はこちらでロード\n",
    "    await piplite.install([\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"statsmodels\", \"scipy\", \"japanize-matplotlib-jlite\"])\n",
    "except ImportError:\n",
    "    # piplite がない環境（通常のローカル Jupyter など）の場合はそのまま進みます。\n",
    "    pass\n",
    "\n",
    "# 必要に応じて micropip を使って純 Python パッケージを追加することもできます。\n",
    "# import micropip\n",
    "# await micropip.install(\"some-pure-python-package\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1de2e",
   "metadata": {},
   "source": [
    "### 0.1 インポートと日本語表示設定\n",
    "\n",
    "グラフ描画や統計モデリングに必要なライブラリをインポートし、\n",
    "日本語が文字化けしないように `japanize_matplotlib_jlite` を最後に読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # グラフ作成の基本ライブラリ\n",
    "import seaborn as sns           # きれいなグラフを簡単に作成できるライブラリ\n",
    "import numpy as np              # 数値計算用ライブラリ（配列や数学関数）\n",
    "import pandas as pd             # データ分析用ライブラリ（表形式のデータ処理）\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "import japanize_matplotlib_jlite  # 必ず最後に読み込む\n",
    "\n",
    "# グラフのスタイル設定（お好みで調整可）\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b9153",
   "metadata": {},
   "source": [
    "## 1. 単回帰分析の基本\n",
    "\n",
    "まず、もっとも基本的な **単回帰分析**（説明変数が 1 つの線形回帰）から始めます。\n",
    "ここでは、架空データとして「身長から体重を予測する」モデルを作ってみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0d93f",
   "metadata": {},
   "source": [
    "### 1.1 ダミーデータの作成\n",
    "\n",
    "NumPy を使って身長と体重のダミーデータを生成し、Pandas の DataFrame にまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b64920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数の再現性のためのシード\n",
    "np.random.seed(42)\n",
    "\n",
    "# 身長（cm）: 平均 165, 標準偏差 10 の正規分布から 100 人分\n",
    "height = np.random.normal(loc=165, scale=10, size=100)\n",
    "\n",
    "# 体重（kg）: 身長にほぼ比例 + ノイズ\n",
    "true_intercept = -60\n",
    "true_slope = 0.8\n",
    "weight = true_intercept + true_slope * height + np.random.normal(loc=0, scale=3, size=100)\n",
    "\n",
    "# DataFrame にまとめる\n",
    "df = pd.DataFrame({\n",
    "    \"height\": height,\n",
    "    \"weight\": weight\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7701cd",
   "metadata": {},
   "source": [
    "### 1.2 散布図の確認\n",
    "\n",
    "まずは **散布図** で身長と体重の関係を視覚的に確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdfdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"height\", y=\"weight\")\n",
    "plt.title(\"身長と体重の散布図\")\n",
    "plt.xlabel(\"身長 (cm)\")\n",
    "plt.ylabel(\"体重 (kg)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff78b4",
   "metadata": {},
   "source": [
    "### 1.3 statsmodels による単回帰モデル\n",
    "\n",
    "`statsmodels.formula.api` の `ols`（ordinary least squares）を用いて、\n",
    "次のようなモデルを推定します。\n",
    "\n",
    "$$ \\text{weight} = \\beta_0 + \\beta_1 \\cdot \\text{height} + \\varepsilon $$\n",
    "\n",
    "フォーミュラ表記では、\n",
    "\n",
    "`weight ~ height`\n",
    "\n",
    "と書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ddae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォーミュラ形式での単回帰モデル\n",
    "model = smf.ols(\"weight ~ height\", data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# 回帰結果のサマリーを表示\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a215b7",
   "metadata": {},
   "source": [
    "### 1.4 推定された係数の解釈\n",
    "\n",
    "推定された回帰係数（切片と傾き）を取り出して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"推定された係数:\")\n",
    "print(result.params)\n",
    "print(\"\\n95% 信頼区間:\")\n",
    "print(result.conf_int())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36351d87",
   "metadata": {},
   "source": [
    "### 1.5 回帰直線の描画\n",
    "\n",
    "散布図の上に、推定された回帰直線を重ねて描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74aae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図\n",
    "sns.scatterplot(data=df, x=\"height\", y=\"weight\", label=\"観測値\")\n",
    "\n",
    "# 回帰直線用の x の範囲\n",
    "x_pred = np.linspace(df[\"height\"].min(), df[\"height\"].max(), 100)\n",
    "X_pred = pd.DataFrame({\"height\": x_pred})\n",
    "\n",
    "# 予測値\n",
    "y_pred = result.predict(X_pred)\n",
    "\n",
    "plt.plot(x_pred, y_pred, color=\"red\", label=\"回帰直線\")\n",
    "plt.title(\"身長と体重の回帰直線\")\n",
    "plt.xlabel(\"身長 (cm)\")\n",
    "plt.ylabel(\"体重 (kg)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2be22",
   "metadata": {},
   "source": [
    "## 2. 残差解析とモデルのチェック\n",
    "\n",
    "回帰分析では、**残差（予測値と実測値の差）** を調べることで、\n",
    "モデルがデータにどの程度適合しているか、仮定がどれくらい満たされているかを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc037128",
   "metadata": {},
   "source": [
    "### 2.1 残差の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca29f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差（実測値 - 予測値）\n",
    "df[\"fitted\"] = result.fittedvalues\n",
    "df[\"resid\"] = result.resid\n",
    "\n",
    "df[[\"height\", \"weight\", \"fitted\", \"resid\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77683760",
   "metadata": {},
   "source": [
    "### 2.2 残差 vs 予測値のプロット\n",
    "\n",
    "理想的には、残差は 0 を中心にランダムに散らばっていることが望ましいです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354546ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df[\"fitted\"], y=df[\"resid\"])\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"予測値\")\n",
    "plt.ylabel(\"残差\")\n",
    "plt.title(\"残差 vs 予測値\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0323d",
   "metadata": {},
   "source": [
    "### 2.3 残差の正規性のチェック（Q-Q プロット）\n",
    "\n",
    "線形回帰モデルでは、誤差項（残差）が正規分布に従うという仮定を置きます。\n",
    "Q-Q プロットを用いて、残差の正規性を視覚的に確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(df[\"resid\"], line=\"45\")\n",
    "plt.title(\"残差の Q-Q プロット\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb382c54",
   "metadata": {},
   "source": [
    "## 3. 信頼区間と予測区間\n",
    "\n",
    "`statsmodels` では、回帰直線に対する **信頼帯** や、\n",
    "新しい観測値の **予測区間** を計算することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bace42f",
   "metadata": {},
   "source": [
    "### 3.1 予測と区間推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測したい身長の値\n",
    "new_height = pd.DataFrame({\"height\": np.linspace(150, 180, 50)})\n",
    "\n",
    "# 予測と信頼区間・予測区間\n",
    "pred = result.get_prediction(new_height)\n",
    "pred_summary = pred.summary_frame(alpha=0.05)  # 95% 信頼水準\n",
    "\n",
    "pred_summary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39868a4d",
   "metadata": {},
   "source": [
    "### 3.2 回帰直線と信頼帯・予測帯の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回帰直線・信頼帯・予測帯をまとめて可視化\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# 元データの散布図\n",
    "sns.scatterplot(data=df, x=\"height\", y=\"weight\", label=\"観測値\", alpha=0.7)\n",
    "\n",
    "# 回帰直線\n",
    "plt.plot(new_height[\"height\"], pred_summary[\"mean\"], color=\"red\", label=\"回帰直線\")\n",
    "\n",
    "# 信頼帯（mean_ci_lower, mean_ci_upper）\n",
    "plt.fill_between(new_height[\"height\"],\n",
    "                 pred_summary[\"mean_ci_lower\"],\n",
    "                 pred_summary[\"mean_ci_upper\"],\n",
    "                 color=\"red\", alpha=0.2, label=\"95% 信頼帯\")\n",
    "\n",
    "# 予測区間（obs_ci_lower, obs_ci_upper）\n",
    "plt.fill_between(new_height[\"height\"],\n",
    "                 pred_summary[\"obs_ci_lower\"],\n",
    "                 pred_summary[\"obs_ci_upper\"],\n",
    "                 color=\"blue\", alpha=0.1, label=\"95% 予測区間\")\n",
    "\n",
    "plt.xlabel(\"身長 (cm)\")\n",
    "plt.ylabel(\"体重 (kg)\")\n",
    "plt.title(\"回帰直線と信頼帯・予測区間\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130e2ae",
   "metadata": {},
   "source": [
    "## 4. t検定・分散分析（ANOVA）の例\n",
    "\n",
    "ここでは、`statsmodels` と `scipy.stats` を併用して、\n",
    "**2群の平均差の検定（t検定）** と、\n",
    "**3群以上の平均差の検定（分散分析：ANOVA）** を簡単に体験します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9f3ce",
   "metadata": {},
   "source": [
    "### 4.1 2群の t検定（scipy.stats.ttest_ind）\n",
    "\n",
    "例として、「従来の学習法」と「新しい学習法」のテスト得点を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a73ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# 従来の学習法グループ（平均 70, 標準偏差 10）\n",
    "traditional = np.random.normal(loc=70, scale=10, size=30)\n",
    "\n",
    "# 新しい学習法グループ（平均 75, 標準偏差 10）\n",
    "new_method = np.random.normal(loc=75, scale=10, size=30)\n",
    "\n",
    "# 対応のない t検定\n",
    "t_stat, p_value = stats.ttest_ind(new_method, traditional)\n",
    "\n",
    "print(\"=== t検定の結果 ===\")\n",
    "print(f\"従来法の平均: {traditional.mean():.2f}\")\n",
    "print(f\"新しい学習法の平均: {new_method.mean():.2f}\")\n",
    "print(f\"t値: {t_stat:.3f}\")\n",
    "print(f\"p値: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7f58c",
   "metadata": {},
   "source": [
    "### 4.2 1要因分散分析（one-way ANOVA）\n",
    "\n",
    "`statsmodels` の `ols` と `anova_lm` を用いて、\n",
    "3つのグループの平均に差があるかどうかを検定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63677b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# 3つのグループのダミーデータ（平均の異なる正規分布）\n",
    "group_A = np.random.normal(loc=65, scale=8, size=30)\n",
    "group_B = np.random.normal(loc=70, scale=8, size=30)\n",
    "group_C = np.random.normal(loc=75, scale=8, size=30)\n",
    "\n",
    "score = np.concatenate([group_A, group_B, group_C])\n",
    "group = ([\"A\"] * 30) + ([\"B\"] * 30) + ([\"C\"] * 30)\n",
    "\n",
    "df_anova = pd.DataFrame({\"score\": score, \"group\": group})\n",
    "\n",
    "# フォーミュラ形式での ANOVA モデル\n",
    "model_anova = smf.ols(\"score ~ C(group)\", data=df_anova).fit()\n",
    "anova_table = anova_lm(model_anova)\n",
    "\n",
    "anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bec3f",
   "metadata": {},
   "source": [
    "### 4.3 グループごとの分布の可視化\n",
    "\n",
    "箱ひげ図を使って、各グループの分布を視覚的に比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_anova, x=\"group\", y=\"score\")\n",
    "plt.xlabel(\"グループ\")\n",
    "plt.ylabel(\"得点\")\n",
    "plt.title(\"グループ別得点の分布\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0971c",
   "metadata": {},
   "source": [
    "## 5. 総合ミニ演習\n",
    "\n",
    "最後に、これまでの内容を組み合わせた **ミニ演習** を行います。\n",
    "自分でコードを書き換えたり、条件を変えてみたりしながら理解を深めてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25214e",
   "metadata": {},
   "source": [
    "### 演習 1：別の説明変数を追加した重回帰モデル\n",
    "\n",
    "1. 身長に加えて、例えば「年齢」や「性別」をダミー変数として追加したダミーデータを作成し、\n",
    "2. `weight ~ height + age` または `weight ~ height + C(sex)` のような **重回帰モデル** を推定してみましょう。\n",
    "3. 係数の解釈や、単回帰モデルとの違いをコメントしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a3e0e",
   "metadata": {},
   "source": [
    "### 演習 2：残差の正規性が崩れるケースを作ってみる\n",
    "\n",
    "1. わざと外れ値（非常に大きな体重など）をいくつか追加したデータを作成し、\n",
    "2. Q-Q プロットや残差プロットを確認してみましょう。\n",
    "3. モデルの仮定が崩れると、どのような問題が生じそうかコメントしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4307fe",
   "metadata": {},
   "source": [
    "### 演習 3：オリジナルデータでの statsmodels 利用\n",
    "\n",
    "1. 自分で集めた小さなデータ（例：学習時間とテスト得点）を DataFrame にまとめ、\n",
    "2. `statsmodels` を使って単回帰・重回帰モデルを推定してみましょう。\n",
    "3. 係数や p値、決定係数（R^2）などを確認し、結果をレポート風にまとめてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d821a463",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "これで、JupyterLite 上での `statsmodels` の基本的な使い方のチュートリアルは終了です。\n",
    "\n",
    "より高度なモデル（ロジスティック回帰、時系列解析、パネルデータ分析など）も、\n",
    "基本的な流れは同じですので、公式ドキュメントや教科書と併せて試してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431d3b9",
   "metadata": {},
   "source": [
    "## 6. ロジスティック回帰（Logistic Regression）\n",
    "\n",
    "ここでは、目的変数が 0/1 の **二値データ** のときに用いられる、\n",
    "**ロジスティック回帰モデル** を `statsmodels` で実行してみます。\n",
    "\n",
    "例として、「学習時間」と「予備校受講の有無」から、\n",
    "テストに **合格（1）するか不合格（0）か** を予測するモデルを考えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04dee55",
   "metadata": {},
   "source": [
    "### 6.1 ダミーデータの作成\n",
    "\n",
    "次のような前提でデータを生成します。\n",
    "\n",
    "- `study_hours`: 1日あたりの平均学習時間（連続変数）\n",
    "- `prep_course`: 予備校受講の有無（0: 受講無し, 1: 受講あり）\n",
    "- `passed`: テスト合否（0: 不合格, 1: 合格）\n",
    "\n",
    "ロジットモデルの真の生成過程は以下のように設定します。\n",
    "\n",
    "$$ \\text{logit}(p) = -3 + 0.6 \\cdot \\text{study\\_hours} + 1.0 \\cdot \\text{prep\\_course} $$\n",
    "\n",
    "ここで $p$ は合格する確率です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e415cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "n = 200\n",
    "\n",
    "# 学習時間（平均5時間、標準偏差2時間くらい）\n",
    "study_hours = np.clip(np.random.normal(loc=5, scale=2, size=n), 0, None)\n",
    "\n",
    "# 予備校受講（40%が受講）\n",
    "prep_course = np.random.binomial(1, 0.4, size=n)\n",
    "\n",
    "# ロジットモデルに基づく合格確率\n",
    "logit_p = -3 + 0.6 * study_hours + 1.0 * prep_course\n",
    "p = 1 / (1 + np.exp(-logit_p))\n",
    "\n",
    "# 合格フラグ（0/1）\n",
    "passed = np.random.binomial(1, p, size=n)\n",
    "\n",
    "df_logit = pd.DataFrame({\n",
    "    \"study_hours\": study_hours,\n",
    "    \"prep_course\": prep_course,\n",
    "    \"passed\": passed\n",
    "})\n",
    "\n",
    "df_logit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c059dc8",
   "metadata": {},
   "source": [
    "### 6.2 合格率と学習時間の関係をざっくり確認\n",
    "\n",
    "学習時間をいくつかの区間に分けて、各区間での平均合格率を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57216f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習時間をビン分割して合格率を集計\n",
    "df_logit[\"hours_bin\"] = pd.cut(df_logit[\"study_hours\"], bins=[0,2,4,6,8,10])\n",
    "agg = df_logit.groupby(\"hours_bin\")[\"passed\"].mean()\n",
    "\n",
    "print(\"学習時間区間ごとの合格率:\")\n",
    "print(agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4de02",
   "metadata": {},
   "source": [
    "### 6.3 statsmodels によるロジスティック回帰\n",
    "\n",
    "`statsmodels.formula.api` の `logit` を使います。\n",
    "\n",
    "フォーミュラ表記：\n",
    "\n",
    "`passed ~ study_hours + C(prep_course)`\n",
    "\n",
    "`C(prep_course)` と書くことで、カテゴリ（ダミー）変数として扱うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰モデル\n",
    "logit_model = smf.logit(\"passed ~ study_hours + C(prep_course)\", data=df_logit)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "logit_result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f287e6",
   "metadata": {},
   "source": [
    "### 6.4 係数の解釈\n",
    "\n",
    "- 切片: 学習時間が 0、予備校受講無しのときの logit（対数オッズ）\n",
    "- `study_hours` の係数: 学習時間が 1 時間増えるときに、合格の log-odds がどれだけ変化するか\n",
    "- `C(prep_course)[T.1]` の係数: 予備校に通っているとき（1）の log-odds が、通っていない場合（0）と比べてどれだけ変化するか\n",
    "\n",
    "オッズ比（exp(係数)）を見ると直感的な解釈がしやすくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 係数とオッズ比\n",
    "params = logit_result.params\n",
    "odds_ratios = np.exp(params)\n",
    "\n",
    "print(\"係数:\")\n",
    "print(params)\n",
    "print(\"\\nオッズ比:\")\n",
    "print(odds_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e203f",
   "metadata": {},
   "source": [
    "### 6.5 予測確率の計算と可視化\n",
    "\n",
    "学習時間の範囲に対して、「予備校あり」と「予備校なし」のそれぞれの合格確率を描画してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93565cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習時間の範囲\n",
    "hours_grid = np.linspace(0, 10, 100)\n",
    "\n",
    "# 予備校あり / なし の2パターン\n",
    "df_pred_no = pd.DataFrame({\"study_hours\": hours_grid, \"prep_course\": 0})\n",
    "df_pred_yes = pd.DataFrame({\"study_hours\": hours_grid, \"prep_course\": 1})\n",
    "\n",
    "# 予測確率\n",
    "pred_no = logit_result.predict(df_pred_no)\n",
    "pred_yes = logit_result.predict(df_pred_yes)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(hours_grid, pred_no, label=\"予備校なし\")\n",
    "plt.plot(hours_grid, pred_yes, label=\"予備校あり\")\n",
    "plt.xlabel(\"学習時間（時間/日）\")\n",
    "plt.ylabel(\"合格確率\")\n",
    "plt.title(\"ロジスティック回帰による合格確率の予測\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae892638",
   "metadata": {},
   "source": [
    "### 6.6 ミニ演習：ロジスティック回帰\n",
    "\n",
    "1. 上のデータ生成過程で、予備校の効果を小さくしたり大きくしたり（係数を変える）して、結果のオッズ比や合格確率のカーブがどう変化するかを確かめてください。\n",
    "2. 説明変数として `study_hours` の 2 乗項（`I(study_hours ** 2)`）を追加したモデルを推定し、曲線的な関係が生じるかどうかを確認してみましょう。\n",
    "3. `passed` を予測するシンプルなルール（例：学習時間が 5 時間以上なら 1 など）を自分で考え、ロジスティック回帰モデルと比較して、どちらがどのような意味で優れていると言えるかをコメントしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a488b2",
   "metadata": {},
   "source": [
    "## 7. 時系列分析（Time Series Analysis）\n",
    "\n",
    "ここでは、`statsmodels` の時系列モジュールを用いて、\n",
    "簡単な **ARIMA モデル** による時系列解析と予測を体験します。\n",
    "\n",
    "例として、「月次売上データ」を想定したダミーの時系列を作成し、\n",
    "傾向（トレンド）と季節性を持つデータに対して ARIMA モデルを当ててみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19207a53",
   "metadata": {},
   "source": [
    "### 7.1 ダミーの月次売上データの作成\n",
    "\n",
    "5年間（60か月）の売上データを作成します。\n",
    "\n",
    "- ベースライン: 200\n",
    "- 緩やかな右肩上がりのトレンド\n",
    "- 12か月周期の季節性\n",
    "- ランダムノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月次データ（日付インデックス）\n",
    "date_index = pd.date_range(start=\"2015-01-01\", periods=60, freq=\"M\")\n",
    "\n",
    "# トレンド + 季節性 + ノイズ\n",
    "trend = np.linspace(0, 50, 60)  # 緩やかな増加\n",
    "seasonal = 20 * np.sin(2 * np.pi * np.arange(60) / 12)  # 12ヶ月周期\n",
    "noise = np.random.normal(loc=0, scale=5, size=60)\n",
    "\n",
    "sales = 200 + trend + seasonal + noise\n",
    "\n",
    "ts = pd.Series(sales, index=date_index)\n",
    "ts.name = \"sales\"\n",
    "\n",
    "ts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b1da1",
   "metadata": {},
   "source": [
    "### 7.2 時系列データの可視化\n",
    "\n",
    "まず、全期間の売上推移をプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()\n",
    "plt.title(\"月次売上データ（ダミー）\")\n",
    "plt.xlabel(\"年月\")\n",
    "plt.ylabel(\"売上\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e09f2",
   "metadata": {},
   "source": [
    "### 7.3 ARIMA モデルの推定\n",
    "\n",
    "`statsmodels.tsa.arima.model` の `ARIMA` クラスを使用します。\n",
    "\n",
    "ここでは例として、簡単のため ARIMA(1,1,1) モデルを当ててみます。\n",
    "\n",
    "※ 実務では ACF/PACF や情報量基準（AIC, BIC）などを用いて次数を選びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adaf08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# ARIMA(1,1,1) モデルの当てはめ\n",
    "arima_model = ARIMA(ts, order=(1, 1, 1))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "arima_result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ea503",
   "metadata": {},
   "source": [
    "### 7.4 予測と将来値のプロット\n",
    "\n",
    "推定した ARIMA モデルを使って、\n",
    "観測期間の続きの 12か月分を予測し、元のデータと合わせて可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測期間（12ヶ月先まで）\n",
    "n_forecast = 12\n",
    "forecast_result = arima_result.get_forecast(steps=n_forecast)\n",
    "forecast_mean = forecast_result.predicted_mean\n",
    "forecast_ci = forecast_result.conf_int()\n",
    "\n",
    "# 結合してプロット\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ts.index, ts, label=\"観測値\")\n",
    "\n",
    "forecast_index = pd.date_range(start=ts.index[-1] + pd.offsets.MonthEnd(),\n",
    "                               periods=n_forecast, freq=\"M\")\n",
    "\n",
    "plt.plot(forecast_index, forecast_mean, label=\"予測値\", color=\"red\")\n",
    "\n",
    "# 予測区間の帯\n",
    "plt.fill_between(forecast_index,\n",
    "                 forecast_ci.iloc[:, 0],\n",
    "                 forecast_ci.iloc[:, 1],\n",
    "                 color=\"red\", alpha=0.2, label=\"予測区間\")\n",
    "\n",
    "plt.xlabel(\"年月\")\n",
    "plt.ylabel(\"売上\")\n",
    "plt.title(\"ARIMA モデルによる売上予測\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace0d61",
   "metadata": {},
   "source": [
    "### 7.5 ミニ演習：時系列モデル\n",
    "\n",
    "1. ARIMA モデルの次数 `(p, d, q)` を変えてみて、AIC や BIC の値がどのように変化するかを確認してみてください。\n",
    "2. 季節性をより強くする、または周期を変える（例：6ヶ月周期にする）などしてダミーデータを作り直し、どのようなモデルがよさそうか考察してみましょう。\n",
    "3. 予測期間を 24か月に延ばした場合、予測区間の幅がどのように変化するかを確認し、「先の将来ほど予測が不確実になる」という直感と照らし合わせてコメントしてみてください。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
